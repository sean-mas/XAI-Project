{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Business Understanding\n",
    "\n",
    "### 1.1 Geschäftlicher Hintergrund\n",
    "\n",
    "In der modernen digitalen Ära sind soziale Medien wie Twitter zu primären Kanälen für Kunden geworden, um Meinungen zu äußern, Feedback zu geben und Bedenken zu Produkten und Dienstleistungen zu teilen. Dies erzeugt einen massiven, kontinuierlichen Strom unstrukturierter Textdaten.\n",
    "\n",
    "Während moderne Deep-Learning-Modelle (wie BERT) in der Lage sind, diese Daten mit hoher Präzision zu klassifizieren, leiden sie unter dem **\"Black-Box\"-Problem**. Für Unternehmen ist es oft nicht nachvollziehbar, *warum* ein Modell eine bestimmte Entscheidung getroffen hat. Diese mangelnde Transparenz hemmt den Einsatz solcher KI-Systeme in kritischen Geschäftsprozessen, da Vertrauen, Nachvollziehbarkeit und die Möglichkeit zur Fehleranalyse fehlen.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell id=\"#VSC-d4b8f05f\" language=\"markdown\">\n",
    "### 1.2 Geschäftliches Problem\n",
    "\n",
    "Das Kernproblem ist nicht mehr nur die Klassifikation von Sentiment an sich, sondern die **fehlende Erklärbarkeit (Explainability)** komplexer Transformer-Modelle.\n",
    "\n",
    "Ohne transparente Erklärungen stehen Stakeholder vor folgenden Herausforderungen:\n",
    "- **Mangelndes Vertrauen:** Warum wurde dieser Tweet als \"negativ\" markiert? War es Sarkasmus oder ein echtes Problem?\n",
    "- **Schwierige Fehleranalyse:** Wenn das Modell falsch liegt, woran lag es? Hat es auf irrelevante Wörter (z.B. Namen) reagiert?\n",
    "- **Compliance & Audit:** In vielen regulierten Bereichen muss nachweisbar sein, wie Entscheidungen zustande kommen.\n",
    "\n",
    "Es besteht die Notwendigkeit, nicht nur ein leistungsfähiges Modell zu entwickeln, sondern auch Methoden zu evaluieren, die Licht in die \"Black Box\" bringen.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell id=\"#VSC-f8b87207\" language=\"markdown\">\n",
    "### 1.3 Geschäftsziele\n",
    "\n",
    "Um dieses Problem zu adressieren, zielt dieses Projekt auf die Entwicklung einer erklärbaren Sentiment-Analyse-Lösung ab.\n",
    "\n",
    "1.  **Primäres Ziel (Modellierung):** Entwicklung eines hochpräzisen Sentiment-Modells basierend auf **BERTweet**, das Tweets aus dem Sentiment140-Datensatz zuverlässig klassifiziert.\n",
    "2.  **Primäres Ziel (Evaluation XAI):** Vergleich und Evaluation von zwei führenden XAI-Methoden (**SHAP** und **Captum/Integrated Gradients**) hinsichtlich ihrer Eignung für den produktiven Einsatz.\n",
    "    - Welche Methode liefert treuherzigere (faithful) Erklärungen?\n",
    "    - Welche Methode ist robuster gegenüber leichten Textänderungen?\n",
    "    - Welche Methode ist effizient genug für den Echtzeit-Einsatz?\n",
    "3.  **Sekundäres Ziel:** Ableitung einer Deployment-Strategie, die Qualität und Geschwindigkeit ausbalanciert.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell id=\"#VSC-d3664a15\" language=\"markdown\">\n",
    "### 1.4 Erfolgskriterien\n",
    "\n",
    "Der Erfolg des Projekts wird anhand quantitativer und qualitativer Kriterien gemessen:\n",
    "\n",
    "- **Modell-Performance:** Das BERTweet-Modell muss eine Accuracy von **> 85%** auf dem Testdatensatz erreichen.\n",
    "- **XAI-Evaluation:**\n",
    "    - **Faithfulness:** Die durch die XAI-Methoden identifizierten \"wichtigen\" Wörter müssen nachweislich den größten Einfluss auf die Modellentscheidung haben (gemessen durch Perturbation/Deletion Tests).\n",
    "    - **Performance:** Es muss klar quantifiziert werden, wie viel Rechenzeit die Erklärungen im Vergleich zur reinen Inferenz kosten.\n",
    "    - **Empfehlung:** Am Ende muss eine klare Empfehlung stehen, welche Methode (oder Kombination) für welches Szenario (Batch vs. Real-time) geeignet ist.\n",
    "</VSCode.Cell>\n",
    "<VSCode.Cell id=\"#VSC-33c64e9b\" language=\"markdown\">\n",
    "### 1.5 Projektplan\n",
    "\n",
    "Dieses Projekt folgt dem Cross-Industry Standard Process for Data Mining (CRISP-DM). Jeder Schritt ist in einem separaten Notebook dokumentiert:\n",
    "\n",
    "1.  **Business Understanding (Dieses Notebook):** Definition der Ziele und des Fokus auf Explainable AI (XAI).\n",
    "2.  **Data Understanding:** Explorative Analyse des Sentiment140-Datensatzes.\n",
    "3.  **Data Preparation:** Bereinigung und Vorbereitung der Daten für das BERT-Training.\n",
    "4.  **Modeling:** Fine-Tuning von BERTweet und Training des Klassifikators.\n",
    "5.  **Evaluation:** Umfassende Evaluation des Modells UND der XAI-Methoden (SHAP vs. Captum).\n",
    "6.  **Deployment:** Theoretisches Konzept für die Produktivsetzung einer erklärbaren KI-Architektur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Machine_Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
